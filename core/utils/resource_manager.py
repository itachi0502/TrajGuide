#!/usr/bin/env python3
"""
SOTA Resource Management System for MolPilot
============================================

This module provides comprehensive resource management to prevent file descriptor
leaks and system resource exhaustion in large-scale molecular generation tasks.

Key Features:
- File descriptor monitoring and management
- Automatic resource cleanup
- Context managers for safe resource usage
- Memory and file handle leak detection
- Emergency resource recovery
- Production-ready monitoring and alerting

Designed specifically for MolPilot's intensive I/O operations:
- Molecular file generation (SDF, PDBQT)
- Docking calculations with temporary files
- Logging and metrics collection
- Model checkpointing and evaluation
"""

import os
import gc
import sys
import psutil
import resource
import threading
import contextlib
import tempfile
import weakref
from typing import Dict, List, Optional, Any, Union
from pathlib import Path
import warnings
from datetime import datetime
import atexit
from collections import defaultdict
import time


class ResourceMonitor:
    """SOTA system resource monitor for MolPilot operations"""
    
    def __init__(self, warning_threshold=0.8, critical_threshold=0.95):
        self.warning_threshold = warning_threshold
        self.critical_threshold = critical_threshold
        self.process = psutil.Process()
        self.initial_fd_count = self.get_fd_count()
        self.max_fd_limit = self.get_fd_limit()
        self.monitoring_active = True
        self._lock = threading.Lock()
        
        # Track resource usage over time
        self.fd_history = []
        self.memory_history = []
        
        # Register cleanup on exit
        atexit.register(self.emergency_cleanup)
        
    def get_fd_count(self) -> int:
        """Get current file descriptor count"""
        try:
            return self.process.num_fds()
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            return 0
    
    def get_fd_limit(self) -> int:
        """Get system file descriptor limit"""
        try:
            soft_limit, hard_limit = resource.getrlimit(resource.RLIMIT_NOFILE)
            return soft_limit
        except (OSError, ValueError):
            return 1024  # Conservative fallback
    
    def get_memory_usage(self) -> Dict[str, float]:
        """Get current memory usage statistics"""
        try:
            memory_info = self.process.memory_info()
            return {
                'rss_mb': memory_info.rss / 1024 / 1024,
                'vms_mb': memory_info.vms / 1024 / 1024,
                'percent': self.process.memory_percent()
            }
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            return {'rss_mb': 0, 'vms_mb': 0, 'percent': 0}
    
    def check_resources(self) -> Dict[str, Any]:
        """Comprehensive resource check"""
        with self._lock:
            current_fd = self.get_fd_count()
            fd_usage_ratio = current_fd / self.max_fd_limit if self.max_fd_limit > 0 else 0
            memory_info = self.get_memory_usage()
            
            # Update history
            timestamp = time.time()
            self.fd_history.append((timestamp, current_fd))
            self.memory_history.append((timestamp, memory_info['rss_mb']))
            
            # Keep only recent history (last 1000 entries)
            if len(self.fd_history) > 1000:
                self.fd_history = self.fd_history[-1000:]
                self.memory_history = self.memory_history[-1000:]
            
            status = {
                'fd_count': current_fd,
                'fd_limit': self.max_fd_limit,
                'fd_usage_ratio': fd_usage_ratio,
                'memory_info': memory_info,
                'status': 'healthy',
                'warnings': [],
                'critical': False
            }
            
            # Check for warnings and critical conditions
            if fd_usage_ratio >= self.critical_threshold:
                status['status'] = 'critical'
                status['critical'] = True
                status['warnings'].append(f"CRITICAL: File descriptor usage at {fd_usage_ratio:.1%}")
            elif fd_usage_ratio >= self.warning_threshold:
                status['status'] = 'warning'
                status['warnings'].append(f"WARNING: File descriptor usage at {fd_usage_ratio:.1%}")
            
            if memory_info['percent'] > 90:
                status['warnings'].append(f"High memory usage: {memory_info['percent']:.1f}%")
            
            return status
    
    def emergency_cleanup(self):
        """Emergency resource cleanup"""
        print("ğŸš¨ Emergency resource cleanup initiated...")
        
        # Force garbage collection
        gc.collect()
        
        # Close any remaining file handles
        try:
            # Get list of open files
            open_files = self.process.open_files()
            print(f"ğŸ“ Found {len(open_files)} open files during cleanup")
            
            # Log open files for debugging
            temp_files = [f for f in open_files if '/tmp/' in f.path]
            if temp_files:
                print(f"ğŸ—‘ï¸  Found {len(temp_files)} temporary files")
                
        except Exception as e:
            print(f"âš ï¸  Error during emergency cleanup: {e}")
        
        print("âœ… Emergency cleanup completed")


class FileHandleManager:
    """SOTA file handle management with automatic cleanup"""
    
    def __init__(self):
        self._open_handles = weakref.WeakSet()
        self._handle_registry = {}
        self._lock = threading.Lock()
        
    def register_handle(self, handle, description: str = "unknown"):
        """Register a file handle for tracking"""
        with self._lock:
            handle_id = id(handle)
            self._handle_registry[handle_id] = {
                'handle': handle,
                'description': description,
                'opened_at': datetime.now(),
                'stack_trace': self._get_stack_trace()
            }
            self._open_handles.add(handle)
    
    def unregister_handle(self, handle):
        """Unregister a file handle"""
        with self._lock:
            handle_id = id(handle)
            if handle_id in self._handle_registry:
                del self._handle_registry[handle_id]
    
    def _get_stack_trace(self) -> str:
        """Get current stack trace for debugging"""
        import traceback
        return ''.join(traceback.format_stack()[-3:-1])  # Skip this method and caller
    
    def get_open_handles_info(self) -> List[Dict]:
        """Get information about currently open handles"""
        with self._lock:
            info = []
            for handle_id, handle_info in self._handle_registry.items():
                try:
                    # Check if handle is still valid
                    handle = handle_info['handle']
                    if hasattr(handle, 'closed') and not handle.closed:
                        info.append({
                            'id': handle_id,
                            'description': handle_info['description'],
                            'opened_at': handle_info['opened_at'].isoformat(),
                            'age_seconds': (datetime.now() - handle_info['opened_at']).total_seconds(),
                            'stack_trace': handle_info['stack_trace']
                        })
                except:
                    # Handle is no longer valid, will be cleaned up
                    pass
            return info
    
    def cleanup_stale_handles(self, max_age_seconds: int = 3600):
        """Cleanup handles that have been open too long"""
        with self._lock:
            current_time = datetime.now()
            stale_handles = []
            
            for handle_id, handle_info in list(self._handle_registry.items()):
                age = (current_time - handle_info['opened_at']).total_seconds()
                if age > max_age_seconds:
                    try:
                        handle = handle_info['handle']
                        if hasattr(handle, 'close') and hasattr(handle, 'closed') and not handle.closed:
                            handle.close()
                            stale_handles.append(handle_info['description'])
                    except:
                        pass
                    del self._handle_registry[handle_id]
            
            if stale_handles:
                print(f"ğŸ§¹ Cleaned up {len(stale_handles)} stale file handles")
                for desc in stale_handles[:5]:  # Show first 5
                    print(f"   - {desc}")
                if len(stale_handles) > 5:
                    print(f"   ... and {len(stale_handles) - 5} more")


@contextlib.contextmanager
def safe_file_operation(filepath: Union[str, Path], mode: str = 'r', description: str = None):
    """
    SOTA context manager for safe file operations with automatic cleanup.
    
    Args:
        filepath: Path to file
        mode: File open mode
        description: Description for tracking
        
    Yields:
        File handle
    """
    filepath = Path(filepath)
    description = description or f"{mode} {filepath.name}"
    
    # Ensure parent directory exists for write operations
    if 'w' in mode or 'a' in mode:
        filepath.parent.mkdir(parents=True, exist_ok=True)
    
    file_handle = None
    try:
        file_handle = open(filepath, mode)
        
        # Register with global handle manager
        if hasattr(safe_file_operation, '_handle_manager'):
            safe_file_operation._handle_manager.register_handle(file_handle, description)
        
        yield file_handle
        
    except Exception as e:
        print(f"âš ï¸  File operation failed for {filepath}: {e}")
        raise
    finally:
        if file_handle is not None:
            try:
                file_handle.close()
                
                # Unregister with global handle manager
                if hasattr(safe_file_operation, '_handle_manager'):
                    safe_file_operation._handle_manager.unregister_handle(file_handle)
                    
            except Exception as e:
                print(f"âš ï¸  Error closing file {filepath}: {e}")


@contextlib.contextmanager
def safe_temp_file(suffix: str = '', prefix: str = 'molpilot_', dir: str = None, delete: bool = True):
    """
    SOTA context manager for safe temporary file operations.
    
    Args:
        suffix: File suffix
        prefix: File prefix
        dir: Directory for temp file
        delete: Whether to delete file on exit
        
    Yields:
        Tuple of (file_handle, file_path)
    """
    temp_file = None
    temp_path = None
    
    try:
        temp_file = tempfile.NamedTemporaryFile(
            suffix=suffix,
            prefix=prefix,
            dir=dir,
            delete=False  # We'll handle deletion manually
        )
        temp_path = temp_file.name
        
        # Register with global handle manager
        if hasattr(safe_file_operation, '_handle_manager'):
            safe_file_operation._handle_manager.register_handle(
                temp_file, f"temp_file {Path(temp_path).name}"
            )
        
        yield temp_file, temp_path
        
    except Exception as e:
        print(f"âš ï¸  Temporary file operation failed: {e}")
        raise
    finally:
        # Ensure file is closed
        if temp_file is not None:
            try:
                temp_file.close()
                
                # Unregister with global handle manager
                if hasattr(safe_file_operation, '_handle_manager'):
                    safe_file_operation._handle_manager.unregister_handle(temp_file)
                    
            except Exception as e:
                print(f"âš ï¸  Error closing temporary file: {e}")
        
        # Delete file if requested and it exists
        if delete and temp_path and os.path.exists(temp_path):
            try:
                os.unlink(temp_path)
            except Exception as e:
                print(f"âš ï¸  Error deleting temporary file {temp_path}: {e}")


# Global instances
_resource_monitor = ResourceMonitor()
_file_handle_manager = FileHandleManager()

# Attach handle manager to context manager function
safe_file_operation._handle_manager = _file_handle_manager


def get_resource_status() -> Dict[str, Any]:
    """Get current resource status"""
    return _resource_monitor.check_resources()


def print_resource_status():
    """Print current resource status"""
    status = get_resource_status()
    
    print(f"ğŸ“Š Resource Status: {status['status'].upper()}")
    print(f"   File Descriptors: {status['fd_count']}/{status['fd_limit']} ({status['fd_usage_ratio']:.1%})")
    print(f"   Memory Usage: {status['memory_info']['rss_mb']:.1f} MB ({status['memory_info']['percent']:.1f}%)")
    
    if status['warnings']:
        for warning in status['warnings']:
            print(f"   âš ï¸  {warning}")


def cleanup_resources():
    """Manual resource cleanup"""
    print("ğŸ§¹ Starting resource cleanup...")
    
    # Cleanup stale file handles
    _file_handle_manager.cleanup_stale_handles()
    
    # Force garbage collection
    collected = gc.collect()
    print(f"ğŸ—‘ï¸  Garbage collected {collected} objects")
    
    # Print final status
    print_resource_status()


def monitor_resources_periodically(interval: int = 60):
    """Start periodic resource monitoring (for long-running processes)"""
    def monitor_loop():
        while _resource_monitor.monitoring_active:
            status = get_resource_status()
            if status['critical']:
                print("ğŸš¨ CRITICAL: Resource usage too high!")
                print_resource_status()
                cleanup_resources()
            elif status['status'] == 'warning':
                print("âš ï¸  Resource usage warning")
                print_resource_status()
            
            time.sleep(interval)
    
    monitor_thread = threading.Thread(target=monitor_loop, daemon=True)
    monitor_thread.start()
    print(f"ğŸ“Š Started resource monitoring (interval: {interval}s)")


# Export main functions
__all__ = [
    'ResourceMonitor', 'FileHandleManager', 'safe_file_operation', 'safe_temp_file',
    'get_resource_status', 'print_resource_status', 'cleanup_resources',
    'monitor_resources_periodically'
]
